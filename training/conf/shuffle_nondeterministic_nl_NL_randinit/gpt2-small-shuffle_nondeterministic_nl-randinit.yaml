# gpt2-small-shuffle_nondeterministic_nl-randinit.yaml
#   Configuration for the GPT-2 Small Model.
---
model:
    id: "gpt2-small"

    # Boolean whether to use the pre-existing Hugging Face AutoTokenizer (or train a new one from scratch)
    pretrained_tokenizer: false
    passthrough_tokenizer: true

    # Sequence Length
    seq_len: 1024

    # Stability
    reorder_and_upcast_attn: true
    scale_attn_by_inverse_layer_idx: true

    # Initialize Weights from File
    initial_weights: null
    
    # Configure Model From File
    config_path:  /scratch/xiulyang/multilingual-LM/mistral/conf/models/gpt2-small-NL.json